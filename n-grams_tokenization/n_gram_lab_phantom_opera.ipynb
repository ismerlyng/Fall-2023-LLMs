{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "47cbb3ff",
   "metadata": {},
   "source": [
    "# Ngrams lab\n",
    "September 17\n",
    "Building n-gram model of Phantom of the Opera text (txt) file. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "da2e9da4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\ismer\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# PART 1: setting up and importing \n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "import nltk\n",
    "# if you haven't downloaded punkt before, you only need to run the line below once \n",
    "nltk.download('punkt')\n",
    "from nltk import word_tokenize\n",
    "from nltk import sent_tokenize\n",
    "\n",
    "from nltk.util import bigrams\n",
    "from nltk.lm.preprocessing import padded_everygram_pipeline\n",
    "\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "2b0cfb38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Project Gutenberg EBook of The Phantom of the Opera, by Gaston Leroux    This eBook is for the u\n"
     ]
    }
   ],
   "source": [
    "# you will need to leverage the requests package\n",
    "r = requests.get(r'https://www.gutenberg.org/files/175/175.txt')\n",
    "phantom_opera = r.text\n",
    "\n",
    "# first, remove unwanted new line and tab characters from the text\n",
    "for char in [\"\\n\", \"\\r\", \"\\d\", \"\\t\"]:\n",
    "    phantom_opera = phantom_opera.replace(char, \" \")\n",
    "\n",
    "# check\n",
    "print(phantom_opera[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "7550498f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove the metadata at the beginning - this is slightly different for each book\n",
    "phantom_opera = phantom_opera [985:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "bcc1a1ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PART 2: creating bigram\n",
    "# 2 is for bigrams\n",
    "n = 2\n",
    "#specify the text you want to use\n",
    "text = phantom_opera"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "01f8a147",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['be', 'difficult', 'to', 'find', 'at', 'the', 'present', 'day', ',', 'in', 'the', 'foyer', 'of', 'the', 'ballet', ',', 'old', 'men', 'of', 'the', 'highest', 'respectability', ',', 'men', 'upon', 'whose', 'word', 'one', 'could', 'absolutely', 'rely', ',', 'who', 'would', 'remember', 'as', 'though', 'they', 'happened', 'yesterday', 'the', 'mysterious', 'and', 'dramatic', 'conditions', 'that', 'attended', 'the', 'kidnapping', 'of', 'christine', 'daae', ',', 'the', 'disappearance', 'of', 'the', 'vicomte', 'de', 'chagny', 'and', 'the', 'death', 'of', 'his', 'elder', 'brother', ',', 'count', 'philippe', ',', 'whose', 'body', 'was', 'found', 'on', 'the', 'bank', 'of', 'the', 'lake', 'that', 'exists', 'in', 'the', 'lower', 'cellars', 'of', 'the', 'opera', 'on', 'the', 'rue-scribe', 'side', '.']\n"
     ]
    }
   ],
   "source": [
    "# step 1: tokenize the text into sentences\n",
    "sentences = nltk.sent_tokenize(text)\n",
    "\n",
    "# step 2: tokenize each sentence into words\n",
    "tokenized_sentences = [nltk.word_tokenize(sent) for sent in sentences]\n",
    "\n",
    "# step 3: convert each word to lowercase\n",
    "tokenized_text = [[word.lower() for word in sent] for sent in tokenized_sentences]\n",
    "\n",
    "#notice the sentence breaks and what the first 10 items of the tokenized text\n",
    "print(tokenized_text[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "1199ab34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " be difficult\n"
     ]
    }
   ],
   "source": [
    "# notice what the first 10 items are of the vocabulary - changed to 13 to print full word\n",
    "print(text[:13])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "6fb52586",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we imported this function from nltk\n",
    "train_data, padded_sents = padded_everygram_pipeline(n, tokenized_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "79af78ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.lm import MLE\n",
    "# we imported this function from nltk linear models (lm) \n",
    "# it is for Maximum Likelihood Estimation\n",
    "\n",
    "# MLE is the model we will use\n",
    "lm = MLE(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "b7eb4faf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# currently the vocab length is 0: it has no prior knowledge\n",
    "len(lm.vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "57548db7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7110"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit the model \n",
    "# training data is the bigrams and unigrams \n",
    "# the vocab is all the sentence tokens in the corpus \n",
    "\n",
    "lm.fit(train_data, padded_sents)\n",
    "len(lm.vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "7a9e298f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('be', 'difficult', 'to', 'find', 'at', 'the', 'present', 'day', ',', 'in', 'the', 'foyer', 'of', 'the', 'ballet', ',', 'old', 'men', 'of', 'the', 'highest', 'respectability', ',', 'men', 'upon', 'whose', 'word', 'one', 'could', 'absolutely', 'rely', ',', 'who', 'would', 'remember', 'as', 'though', 'they', 'happened', 'yesterday', 'the', 'mysterious', 'and', 'dramatic', 'conditions', 'that', 'attended', 'the', 'kidnapping', 'of', 'christine', 'daae', ',', 'the', 'disappearance', 'of', 'the', 'vicomte', 'de', 'chagny', 'and', 'the', 'death', 'of', 'his', 'elder', 'brother', ',', 'count', 'philippe', ',', 'whose', 'body', 'was', 'found', 'on', 'the', 'bank', 'of', 'the', 'lake', 'that', 'exists', 'in', 'the', 'lower', 'cellars', 'of', 'the', 'opera', 'on', 'the', 'rue-scribe', 'side', '.')\n"
     ]
    }
   ],
   "source": [
    "# inspect the model's vocabulary. \n",
    "# be sure that a sentence you know exists (from tokenized_text) is in the \n",
    "print(lm.vocab.lookup(tokenized_text[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "61b7b185",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('be', 'difficult', 'to', 'find', 'at', 'the', '<UNK>', '.')\n"
     ]
    }
   ],
   "source": [
    "# see what happens when we include a word that is not in the vocab. \n",
    "print(lm.vocab.lookup('be difficult to find at the tiktok .'.split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "30c4cb80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "3.365785111449559e-05"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# how many times does phantom appear in the model?\n",
    "print(lm.counts['phantom'])\n",
    "\n",
    "# what is the probability of phantom appearing? \n",
    "# this is technically the relative frequency of phantom appearing \n",
    "lm.score('phantom')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "0ba80f3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# how often does (phantom, and) occur and what is the relative frequency?\n",
    "print(lm.counts[['phantom']]['and'])\n",
    "lm.score('and', 'phantom'.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "309efdf7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# what is the score of 'UNK'? \n",
    "\n",
    "lm.score(\"<UNK>\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "fa55c028",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['my', 'allowance', '.', '</s>', 'render', 'playful', '.', \"''\", '</s>', \"'s\", 'death', '.', \"''\", '</s>', 'no', 'longer', 'against', 'the', 'stalls', ',']\n"
     ]
    }
   ],
   "source": [
    "# generate a 20 word sentence starting with the word, 'ghost'\n",
    "\n",
    "print(lm.generate(20, text_seed= 'ghost', random_seed=42))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "592b9d21",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize.treebank import TreebankWordDetokenizer\n",
    "\n",
    "detokenize = TreebankWordDetokenizer().detokenize\n",
    "\n",
    "def generate_sent(lm, num_words, text_seed, random_seed=42):\n",
    "    \"\"\"\n",
    "    :param model: An ngram language model from `nltk.lm.model`.\n",
    "    :param num_words: Max no. of words to generate.\n",
    "    :param random_seed: Seed value for random.\n",
    "    \"\"\"\n",
    "    content = []\n",
    "    for token in lm.generate(num_words, text_seed=text_seed, random_seed=random_seed):\n",
    "        if token == '<s>':\n",
    "            continue\n",
    "        if token == '</s>':\n",
    "            break\n",
    "        content.append(token)\n",
    "    return detokenize(content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "54c65b9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'my allowance.'"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now generate sentences that look much nicer. \n",
    "generate_sent(lm, 20, text_seed='ghost', random_seed = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "5fd8499a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'my allowance.'"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Generating more sentences\n",
    "generate_sent(lm, 50, text_seed='They', random_seed = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbcea0ec",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
